---
title: 딥러닝의 탄생과 활용
author: dapin1490
date: 2021-11-22 00:00:00 +09:00
categories: [IT, Machine Learning]
tags: [지식, IT, 딥러닝]
render_with_liquid: false
---

### 게임과 인공지능
   
-----
  
<br>
  
\* 대학 과제로 작성된 글이며, IT 계열 전공 1학년생 수준으로 쓰였음을 알림.   
   
   
   
### 목차    
<p>1. 서론<br>
2-1. 인공지능<br>
2-2. 딥러닝<br>
3. 게임과 인공지능</p>    
  
<br><br><br>   
     
### 1. 서론   
   
<br>   
  
코로나19의 영향으로 비대면 콘텐츠가 나날이 늘어나고 있는 요즘, 많은 이들이 한 번쯤 게임을 즐겨본 적이 있을 것이다. 게임은 RPG, 액션, 퍼즐 등 다양한 장르에 걸쳐 있으며 실제 시장에 출시된 작품은 셀 수조차 없이 많다. 이 중에는 인공지능이 사용되는 부분도 있다. 이 글에서는 게임에 사용된 인공지능과 딥러닝 사례를 통해 인공지능에 대해 알아보며 딥러닝이란 무엇인지 소개할 것이다.   
   
<br><br>
  
### 2-1. 인공지능   
    
<br>
  
인공지능이란 간단히는 컴퓨터나 다른 도구를 사용하여 인위적으로 만든 지능, 조금 다르게 말하자면 지금 이 순간 사람이 잘하는 것을 컴퓨터가 할 수 있도록 하는 연구와 그 결과물을 말한다. 영어로는 Artificial Intelligence라고 하며 보통 AI라고 부른다. 말 그대로 인공적인 지능인 만큼 인공지능은 지능적인 행동을 할 것을 기대받는데, 이때 지능적인 행동은 인지, 추론, 학습, 의사소통, 복합적인 상황에서 행동하기 등을 말한다. 언젠가는 단지 지능적인 행동을 넘어 사람만큼, 혹은 사람보다 주어진 일을 잘하고 행동을 이해하는 인공지능을 만드는 것이 인공지능 연구의 목표이다.   
   
인공지능은 몇 가지 기준에 따라 여러 가지로 분류할 수 있다. 이 글에서는 기호 기반 AI와 비기호 AI에 대해 알아보도록 하겠다. 우선 기호 기반 AI는 고전적인 AI로 사전 지식과 대전제에 기반한 논리와 미리 설계된 행동을 바탕으로 한다. 사람이 지식을 넣어주지 않으면 지능적인 행동을 할 수 없다. 또한 기호 기반 AI의 지식 접근 방식은 탑다운(top-down)이라고 하는데, 어떠한 대전제로부터 하위의 것을 이끌어내는 방식이다. 지식을 인간의 문장 수준으로 입력하고, 그것을 LISP이라는 언어로 리스트로 만들어 기호처리를 함으로써 이루어진다.   
   
비기호 AI는 기호 기반 AI에 비해 비교적 현대적인 AI이다. 지능적 행동은 기호적 과정이 아니라 비기호적 처리의 결과로 나타나는 것이라는 입장을 갖는다. 생물체의 지능 작용을 모방하여 만든 신경망이 여기에 속하며 생물학적 AI라고도 한다. 지식에 대한 접근 방식도 기호 기반 AI와 상반되게 나타나는데, 인간이 완성된 지식을 제공하지 않고 AI가 학습하게 하며 개별적 경험으로부터 일반화된 개념을 찾는 바텀업(bottom-up) 방식을 취한다. 이를 통해 인간이 설계하지 않은 행위가 나타나도록 한다. 이것을 창발 행위라고 한다. 비기호 AI는 가장 낮은 수준의 지식으로 기호 대신 신호를 사용한다.   
   
앞선 설명만으로 보면 기호 기반 AI보다 비기호 AI(이후 생물학적 AI라고 칭한다)가 훨씬 좋은 것으로 보일 수 있다. 그러나 둘은 방식이 다를 뿐 어느 하나가 정답은 아니라는 것을 두 AI의 역사를 간단히 짚어보며 알아보도록 하겠다.   
   
먼저 기호 기반 AI의 역사부터 살펴보자. 우리가 지금 익숙하게 부르고 있는 인공지능(Artificial Intelligence)이라는 말은 1956년 기호 기반 AI 측에서 만들어졌다. 위에서 언급한 LISP이라는 프로그래밍 언어도 1958년에 만들어졌으며 이외에 PROLOG(1970)라는 언어도 있다. 주요한 업적 중 하나는 1973년 MYCIN이라는 전문가 시스템을 만든 것인데, 전문가 시스템이란 특정 분야에 대해서만은 사람보다 뛰어난 인공지능을 만들자는 취지에 따라 개발된 인공지능의 일종이다. MYCIN은 감염성 질병을 진단하고, 항생제를 처방하고, 그 추론을 자세히 설명할 수 있는 대화형 프로그램인데, 제한된 테스트에서는 그 성능이 전문의 수준과 같았다고 한다. 1982년부터 1992년까지는 5세대 컴퓨터 시스템 프로젝트를 시도했다. 유감스럽게도 성공하지 못하였고 현재의 컴퓨터는 4세대이다. 1994년에는 지능형 에이전트 연구가 있었다. 지능형 에이전트란 주어진 환경 내에서 어느 정도 자율적으로 위임자를 대신하여 능동적으로 임무를 수행할 수 있는 지능형 프로그램을 말한다. 누군가를 위해 어떠한 일을 대신 한다는 점이 전문가 시스템과 비슷하지만 전문가 시스템보다 좀 더 보편적이고 낮은 수준의 일을 하도록 만들어졌다. 그러나 같은 프로그램으로도 사용자에 따라 다른 일을 할 수 있고 환경이 변화하면 그에 따라 행동도 같이 변화할 수 있다는 특징이 있다.   
   
다음은 생물학적 AI의 역사이다. 1943년에 맥클로피츠의 ‘뉴런’이라는 말이 처음 나왔다. 이어 1959년 퍼셉트론이라는 개념이 등장했고 여기까지가 신경망의 아주 기초적인 부분이다. 이후로 한동안 생물학적 AI 분야에서는 이 인공지능으로 일기예보도 가능할 것이라 생각하였으나 성과는 그리 좋지 못하였다. 1975년에는 유전자 알고리즘이 개발되었다. 유전자 알고리즘은 생물의 유전과 진화 메커니즘을 공학적으로 모델화하여 문제 해결이나 시스템의 학습 등에 응용하려고 한 것으로, 풀어야 할 문제의 해를 특정한 자료구조로 표현한 후 조금씩 변형하여 더 좋은 해를 만들어내는 방식이다. 1986년에는 연결주의가 등장했다. 연결주의는 인공 신경망을 이용하여 심리적 현상이나 기제를 과학적 절차로 구체적으로 구현하는 인지 과학 분야의 접근법이다. 사전 지식을 전혀 주지 않은 ‘백지’ 상태로 경험을 통해 학습하는 것이 특징이다.   
   
<br><br>
   
### 2-2. 딥러닝   
   
<br>
  
딥러닝에 관해 설명하기에 앞서 머신러닝이란 무엇인지 간단히 알아보겠다. 머신러닝은 AI의 하위 분야 중 하나인데, 여러 개의 예시 데이터에서 일반적인 규칙을 찾아내는 자동화된 절차로 구성된다. 이를 예시 데이터로부터 규칙을 학습했다고 말한다. 학습 방식은 예제와 답을 모두 주는 지도 학습과 답은 가르쳐주지 않고 예제만 제공하는 비지도 학습이 있다. 이 과정을 인공 신경망을 사용하여 수행하는 것이 딥러닝이다.   
   
인공 신경망은 생물체의 신경망을 모방한 것으로 인공 뉴런들의 결합으로 만들어진 네트워크가 학습을 통해 결합의 세기를 바꾸어 문제 해결 능력을 갖는 모델 전반을 가리키는 말이지만, 이 글에서는 퍼셉트론을 이용한 모델을 중심으로 알아볼 것이다.   
   
인공 신경망과 딥러닝은 1943년 맥클로와 피츠가 만든 계산학 모델을 그 시점으로 한다. 1954년 MIT에서 팔리와 웨슬리 클라크가 이 모델을 처음으로 사용하였다. 1958년에는 로젠블라트가 퍼셉트론을 만들었다. 다만 이 당시에는 단층 퍼셉트론을 사용하였기 때문에 XOR 연산은 불가하였다. 1969년 발표된 민스키와 페퍼트의 논문으로 인해 한동안 신경망 연구가 침체되었으나 1975년 오차 역전파 알고리즘이 만들어지고 그동안 기술의 발전으로 컴퓨터의 성능이 좋아지면서 그 세(勢)가 회복되었다. 1980년대 중반에는 연결주의가 각광을 받았다. 2000년대 딥러닝이 출현하면서 역사는 지금에 이르렀다.   
   
딥러닝에 사용되는 신경망 구조는 다양하다. 인공지능 수업에서 배운 다층 퍼셉트론을 이용한 신경망도 그중 하나이다. 이 글에서는 심층 신경망과 합성곱 신경망, 순환 신경망에 대해 알아볼 것이다.   
   
우선 심층 신경망은 입력층과 출력층 사이에 여러 개의 은닉층을 갖는 다층 퍼셉트론으로 이루어진 신경망이며 후에 서술할 다른 신경망의 바탕이 된다. 학습은 오류 역전파 알고리즘으로 한다. 이 알고리즘은 입력값과 출력값을 이미 알고 있는 상태에서 사용한다. 신경망에 사용된 각각의 노드를 모두 퍼셉트론으로 간주하고, 초기 가중치는 무작위로 주어진다. 각 노드에서 활성함수를 거쳐 나온 값은 다음 노드의 입력값이 되며 활성함수는 주로 시그모이드 함수를 쓴다. 신경망을 거쳐 나온 결과값과 사용자가 원하는 값 사이의 오차를 구해 이것을 0에 근사시키는 것이 목표이다. 이를 위해 경사 하강법을 쓴다. 경사 하강법은 오차 함수의 기울기가 0이 되는 쪽으로 가중치를 조정하는 방법이다. 다만 이 방법은 항상 전역 최솟값을 구하지는 못한다는 단점이 있다. 전역 최솟값이 아닌 극솟값이라도 마찬가지로 기울기는 0이기 때문에 알고리즘은 이를 구분할 수 없다.   
   
합성곱 신경망은 주로 시각적 영상을 분석하는 데 사용되는 심층 신경망의 일종이다. 크게 합성곱 층(Convolution layer)과 풀링 층(Pooling layer)으로 구성된다. 합성곱 층에서는 처리해야 할 이미지에 대해서 합성곱 연산이라는 것을 하는데, 커널이라는 n\*m 크기의 행렬로 높이와 너비가 a\*b인 이미지를 훑으면서 커널과 겹치는 부분의 이미지와 커널 원소 값을 곱해서 모두 더한 값을 출력으로 하는 연산이다. 이미지의 좌상단부터 시작해 오른쪽으로 우하단까지 진행한다. 커널은 보통 3\*3 또는 5\*5를 쓴다. 이 연산을 통해 나온 결과를 특성 맵이라고 부른다. 물론 커널의 크기도, 커널이 이동할 범위도 사용자가 직접 정할 수 있으나 이 글에서는 3\*3 커널을 한 칸씩 움직이는 경우를 기준으로 설명하겠다. 앞서 설명한 바와 같이 합성곱 연산을 거치고 나면 이미지의 크기가 작아질 수밖에 없게 되는데 이를 방지하기 위해 패딩(padding)을 사용할 수 있다. 입력에 사용될 이미지의 가장자리에 사용할 커널의 크기에 맞게 테두리를 추가하는 것이다. 주로 0으로 채워 넣는 제로 패딩을 사용한다. 3\*3 커널을 한 칸씩 움직이는 경우에는 패딩 또한 한 칸만 추가하면 된다. 심층 신경망으로 이 연산을 수행할 때에는 입력 이미지가 입력층이 되고 커널이 가중치, 특성 맵이 결과값이 된다.   
   
풀링 층에서는 합성곱 층에서 나온 특성 맵을 다운샘플링하여 특성 맵의 크기를 줄이는 연산이 수행된다. 그 방식은 보통 최대 풀링과 평균 풀링 두 가지가 있다. 풀링에서도 합성곱 연산과 마찬가지로 커널을 갖는데, 특성 맵에서 커널 만큼의 영역 중 최댓값을 찾아 출력한다면 최대 풀링, 평균값을 계산하여 출력한다면 평균 풀링이 된다. 풀링 연산에서 가중치는 없다.   
   
순환 신경망은 입력과 출력을 시퀀스(Sequence) 단위로 처리하는 모델이다. 시퀀스 모델은 여러 가지가 있으나 이 글에서는 RNN(Recurrent Neural Network)에 관해 설명하겠다. 이전까지 설명한 신경망 모델들은 모두 입력과 출력이 하나의 방향으로만 진행되었다. 이를 피드 포워드(Feed Forward)라고 한다. 순환 신경망은 이와 달리 자신의 출력을 결과 방향으로 보내는 동시에 노드에 저장해 두었다가 다시 자신의 입력으로 사용한다. 이렇게 자신의 값을 기억하는 노드를 메모리 셀이라고 부르며 기억한 값은 은닉 상태(hidden state)라고 하고 이 때문에 입력값에 대해 한 개, 은닉 상태에 대해 한 개씩 총 두 개의 가중치를 갖는다. 또한 이 모델에서는 그 특성상 시점(t)의 구분이 있다. 이 모델을 나타내는 모식도는 아래와 같다. x는 입력, y는 출력이며 편향은 생략되었다.   
   
<figure style="text-align:center">
<img src="/assets/img/category-it/211209-1-RNNcell.png">
    <figcaption>[그림 1] 순환 신경망 모식도</figcaption>
</figure>
  
[그림 1]에서 초록색 셀이 메모리 셀이며 그 위에 그려진 자신의 셀에서 나와 되돌아가는 화살표가 은닉 상태를 나타낸다. 이 모델은 입력과 출력의 길이를 다르게 설계해 다양한 용도로 사용할 수 있다. 예를 들어 여러 개의 입력에 대해 하나의 출력을 내는 경우 문서의 긍정/부정 판별 또는 스팸 메일 판별을 수행하게 할 수 있고, 하나의 입력에 대해 여러 개의 출력을 내는 경우 하나의 이미지 입력에 대해 그것의 제목을 출력하도록 할 수 있다.   
  
<br><br>   
    
### 3. 게임과 인공지능   
    
<br>
  
이제 인공지능이 실제로 활용된 사례를 보도록 하겠다. 이 글에서 소개할 사례는 크게 네 가지로 각각 넷마블의 콜럼버스 프로젝트와 마젤란 프로젝트, 구글의 게임 플레이 테스트용 인공지능, 엔씨소프트의 게임 \<블레이드 & 소울\>의 ‘무한의 탑’ 던전에 사용된 비무 AI이다. 글의 말미에는 게임 이외에도 대중에게 잘 알려진 성공 사례에 대해 알아보겠다.   
   
넷마블 콜럼버스 프로젝트는 넷마블의 글로벌 이용자 데이터를 기반으로 하는 AI 프로젝트이다. 프로젝트의 목표는 게임 내 이용자의 유입부터 이탈까지 그 생애 구간에 대한 분석과 관리를 통해 게임 PLC(Product Life Cycle, 제품 수명 주기) 개선을 이루어내는 것이다. 특히 이상징후 탐지를 진행하는데, 이것은 게임 로그를 딥러닝 알고리즘으로 학습해 게임 내에서 발생한 이상 상황을 빠르게 탐지하고 그것을 자동으로 담당자에게 보고하는 시스템이다. 탐지된 이상 상황은 시뮬레이션으로 재현되어 실제로 가능한 플레이인지, 게임 시스템을 악용하여 불법적인 이득을 취하는 어뷰징인지 시스템이 자동으로 검증한다. 2020년 기준 넷마블은 이 시스템을 다양한 악용 사례 및 핵 프로그램 확산 방지, 게임의 안정적인 운영과 게임 지표 왜곡 방지 등에 활용하고 있다. 넷마블 측에서는 이 기술을 적용하고 어뷰징 탐지율이 최대 10배 가까이 높아졌다고 하였다. 게임은 많은 사람이 상호작용하며 여러 가지 일이 발생할 수 있는 매체인 만큼, 부적절한 방식으로 게임을 플레이하는 사람을 훨씬 빠르고 정확하게 찾아낼 수 있는 이 기술은 앞으로도 게임 운영에 적잖은 도움이 될 수 있으리라 생각한다. 더불어 이상 상황을 탐지하며 얻은 데이터는 플레이어들의 이용 경향을 파악하고 추후 콘텐츠를 기획하는 데에도 참고가 될 것으로 보인다.    
   
콜럼버스 프로젝트가 이미 만들어진 게임의 운영에 도움을 주었다면 마젤란 프로젝트는 게임의 유지/보수와 업데이트를 맡았다. 이 프로젝트는 지능형 게임을 만드는 데 중점을 두었다고 하는데, 여기서 지능형 게임이란 AI 플레이어가 인간 플레이어의 패턴을 학습해 지속적으로 재미 요소를 제공하는 것을 말한다. 이를 통해 게임 몰입도 향상 효과를 얻을 수 있다. AI 플레이어는 또한 게임 밸런스 조정과 QA(Quality Assurance) 등 관련 업무에 도움을 준다. 넷마블은 이 프로젝트를 통해 게임 테스트 자동화 시스템을 도입했다. 그 효과로 버그 발견 확률이 높아지고, 수정 후 테스트 작업에서도 속도가 최대 40% 개선되었다고 한다. 이 기술은 콘텐츠 제작 비용 감소와 제작 기간 단축 등에도 유용하였으며 보스 및 던전 난이도 측정에도 활용한다고 한다. 넷마블은 2020년 기준 서비스 중인 일부 게임에 이 기술을 적용하고 있다.   
   
게임을 해봤다면 버그에 대해서도 들어본 바가 있을 것이다. 개발자와 플레이어 모두에게 버그는 대부분 골칫덩이라는 건 당연한 사실이다. 여기 그런 개발자를 위한 AI가 있다. 구글 AI 연구팀이 오픈소스로 배포한 비디오 게임 개발 테스트용 AI 솔루션이다. 이전에도 AI는 종종 게임 테스트에 활용되곤 했지만 보통 강화학습 알고리즘을 사용했고, 이는 많은 데이터를 필요로 하고 개발자에게 높은 수준의 머신러닝 지식을 요구한다는 단점이 있었다. 하지만 구글에서 배포한 이 AI는 모방학습 알고리즘을 사용하여, 개발자가 머신러닝에 대한 전문지식이 부족하더라도 단지 스스로 게임을 플레이해 보이는 것만으로 문제점을 찾을 수 있다. 이것을 이용하여 개발자는 인간 테스터가 좀 더 복잡하고 어려운 문제에 집중하도록 도울 수 있다. 지원되는 장르는 아케이드, 액션/어드벤처 및 레이싱 게임이다. 이 사례는 앞서 언급한 것들과 달리 오픈소스로 배포되어 활용성이 상당히 높다. 마젤란 프로젝트와 그 기능이 비슷하지만 범용성이 높고 사용이 용이하다는 점에서 앞으로도 많은 개발자들이 이용할 것으로 보인다.   
   
\<블레이드 & 소울\>(이하 블소라고 칭한다)은 2012년 서비스를 시작한 엔씨소프트의 게임이다. 동양 판타지를 시작으로 하여 중세 서양 판타지로 나아가는 세계관을 그 특징으로 한다. 그 장르가 RPG인 만큼 던전은 빠질 수 없는 요소인데, 이 중 ‘무한의 탑’이라는 던전에 AI 기술이 사용되었다. 지난 2016년 엔씨소프트에서는 블소에서 신규 콘텐츠 ‘무한의 탑’ 업데이트를 진행했다. 1인용 던전이며 각 층마다 각기 다른 기술을 사용하는 NPC(Non-Player Character)가 적으로 등장하는데, 이 NPC가 정해진 패턴만을 반복하지 않고 플레이어 간 대전에서 발생한 다양한 상황을 바탕으로 플레이어에게 대응하는 AI라고 한다. 해당 NPC는 플레이어와 동일한 기술을 사용하며, 플레이어의 실력과 플레이한 난이도에 따라 다음 층의 높이와 NPC의 실력이 달라진다. 엔씨소프트 측에서는 이 콘텐츠가 플레이어 간 대전이 아님에도 마치 사람과 전투를 하는 듯한 긴장감과 재미를 제공할 것으로 기대하였으나 유감스럽게도 NPC의 스킬 쿨타임이 무시되는 버그가 발생하거나 NPC가 오히려 이런저런 버그를 악용하는 문제로 플레이어들에게 원성이 자자한 콘텐츠이다. 플레이어로부터 배우고 성장하는 NPC를 만들겠다는 그 의도는 높이 평가하지만 콘텐츠 출시 후 발견된 여러 문제와 버그를 고쳤다는 소식을 볼 수 없었던 것은 유감스럽다. 그러나 그것은 지속적인 업데이트의 부재로 생긴 문제이고, 이 NPC를 만들었던 기술은 앞으로도 활용 가능성이 높으리라 생각한다.   
   
이전부터 인공지능은 다양한 분야에서 활용되어왔으며 지금도 그러하고 있다. 인간 바둑 기사를 이긴 알파고나 체스 인공지능 딥블루, 현재 번역기로 널리 사용되고 있는 파파고 등이 그 예시이다. 알파고는 구글의 딥마인드에서 딥러닝과 강화학습 기술로 개발하였으며 2018년 12월에 바둑을 포함한 보드게임에 적용할 수 있는 범용 인공지능 알파 제로(Alpha Zero)도 발표되었다. 딥블루는 IBM이 만들었으며 체스에서 가능한 다음 수들을 탐색하여 인간과 대결하였다. 일반적으로 알려진 ‘딥블루’가 인간을 이겼다는 명성과는 달리, ‘딥블루’는 인간을 이기지 못했고 이후 개발된 딥블루의 개량형 ‘디퍼 블루(Deeper Blue)’가 정식으로 체스 세계 챔피언을 이겼다. 파파고는 네이버에서 개발한 무료 번역 서비스로 네이버가 자체 개발한 인공 신경망을 그 기반으로 한다. 아직까지도 완벽하다고는 할 수 없지만 출시 이후 수많은 사람들의 이용과 번역 도움으로 꾸준히 발전해나가고 있다. 비교적 옛날에 개발된 딥블루와 디퍼 블루는 지속적인 발전을 기대하기 어렵지만 ‘최초의 승리’였다는 점에서 그 의의를 갖는다고 생각한다. 그리고 알파고는 딥블루의 뒤를 이어 인간을 이겼다는 의의와 함께 바둑이라는, 체스보다 훨씬 복잡한 문제를 풀어내었다는 기술의 발전상까지 확인할 수 있는 지표라고 본다. 또한 이후 더 보편적인 보드게임에 적용할 수 있는 알파 제로도 발표되었다고 하니 승리에서 그치지 않고 더 나아간 것을 볼 수 있다. 파파고는 빈번한 이용은 물론 지금도 간혹 예상치 못한 번역으로 사람들 사이에서 회자되고 있다. 일례로 이전에 속칭 ‘야민정음’이라고 하는 것을 파파고가 번역해냈다며 놀라워하는 SNS 게시물이 사람들의 이목을 끈 적이 있다.   
   
<br><br><br>
   
**\* 참고문헌**   
- 인공지능(이 과제가 출제된 강의임) 강의 자료
- “MYCIN” AI Study [http://www.aistudy.co.kr/demo/MYCIN.htm](http://www.aistudy.co.kr/demo/MYCIN.htm)
- “Intelligent Agents” STUDYLIB [https://studylib.net/doc/9074467/intelligent-agents](https://studylib.net/doc/9074467/intelligent-agents)
- “지능형 에이전트” 위키백과, 우리 모두의 백과사전. [https://ko.wikipedia.org/wiki/지능형_에이전트](https://ko.wikipedia.org/wiki/%EC%A7%80%EB%8A%A5%ED%98%95_%EC%97%90%EC%9D%B4%EC%A0%84%ED%8A%B8)
- “유전자 알고리즘 : 정환묵” AI Study [http://www.aistudy.co.kr/biology/genetic/genetic_jeong.htm](http://www.aistudy.co.kr/biology/genetic/genetic_jeong.htm)
- “연결주의” 위키백과, 우리 모두의 백과사전. [https://ko.wikipedia.org/wiki/연결주의](https://ko.wikipedia.org/wiki/%EC%97%B0%EA%B2%B0%EC%A3%BC%EC%9D%98)
- “딥 러닝이란 무엇인가요?” Basler [https://www.baslerweb.com/ko/vision-campus/markets-and-applications/what-is-deep-learning/](https://www.baslerweb.com/ko/vision-campus/markets-and-applications/what-is-deep-learning/)
- “딥 러닝” 위키백과, 우리 모두의 백과사전. [https://ko.wikipedia.org/wiki/딥_러닝](https://ko.wikipedia.org/wiki/%EB%94%A5_%EB%9F%AC%EB%8B%9D)
- “딥러닝 기초 - 오차역전파(back propagation) 알고리즘” goofcode’s blog [https://goofcode.github.io/back-propagation](https://goofcode.github.io/back-propagation)
- “인공 신경망” 위키백과, 우리 모두의 백과사전. [https://ko.wikipedia.org/wiki/인공_신경망](https://ko.wikipedia.org/wiki/%EC%9D%B8%EA%B3%B5_%EC%8B%A0%EA%B2%BD%EB%A7%9D)
- “합성곱 신경망” 위키백과, 우리 모두의 백과사전. [https://ko.wikipedia.org/wiki/합성곱_신경망](https://ko.wikipedia.org/wiki/%ED%95%A9%EC%84%B1%EA%B3%B1_%EC%8B%A0%EA%B2%BD%EB%A7%9D)
- “딥 러닝을 이용한 자연어 처리 입문” WikiDocs [https://wikidocs.net/book/2155](https://wikidocs.net/book/2155)
- “넷마블 '콜롬버스·마젤란' 프로젝트 아시나요” BUSINESS WATCH [http://news.bizwatch.co.kr/article/mobile/2020/10/30/0021](http://news.bizwatch.co.kr/article/mobile/2020/10/30/0021)
- “블레이드&소울, ‘무한의 탑’ 업데이트…강력한 AI NPC 등장” smartPC사랑 [https://www.ilovepc.co.kr/news/articleView.html?idxno=12283](https://www.ilovepc.co.kr/news/articleView.html?idxno=12283)
- “[AI 리뷰] 인공지능을 통해 게임 플레이 에이전트를 빠르게 학습하고, 배포할 수 있는 솔루션 오픈소스로 공개” 인공지능신문 [http://www.aitimes.kr/news/articleView.html?idxno=21550](http://www.aitimes.kr/news/articleView.html?idxno=21550)
- “BARO AI Academy“ facebook [https://pixel.facebook.com/baro.aiacademy/posts/382616146530069](https://pixel.facebook.com/baro.aiacademy/posts/382616146530069)
- ”알파고“ 위키백과, 우리 모두의 백과사전. [https://ko.wikipedia.org/wiki/알파고](https://ko.wikipedia.org/wiki/%EC%95%8C%ED%8C%8C%EA%B3%A0)
   
<br><br><br>   
  
사담 : 나 이거 쓸 때는 나름 노력한다고 여기저기 찾고 고민하면서 열심히 쓴 건데.. 복붙하니까 금방이네. 좀 허무하고 그렇다. 오늘 인공지능 기말고사 보고 종강해서 강의자료 정리하다 발견해서 올림. 내가 소설을 써도 이만큼 많이 쓴 적이 없는데 그럼 남겨야 하지 않겠니 이게 또 어디서 쓸 데가 있을 줄 알고.   
   
원래 이 과제가 이런저런 지식 서술도 기본 요구사항이었지만 학생 본인 의견도 쓰라고 했거든? 그래서 나도 어떻게든 말을 만들어서 붙이긴 했는데 솔직히 근거 없고 뻔히 입발린 말이라서 그건 적당히 지우고 올린다.   